#### Redis 是单线程还是多线程？

这个问题应该已经看到过无数次了，最近 redis 6 出来之后又被翻出来了。

**redis 4.0 之前**，redis 是**完全单线程**的。

**redis 4.0 时**，redis 引入了多线程，但是**额外的线程只是用于后台处理**，例如：删除对象。**核心流程还是完全单线程的**。这也是为什么有些人说 4.0 是单线程的，因为他们指的是核心流程是单线程的。

这边的**核心流程**指的是 redis 正常处理客户端请求的流程，通常包括：**接收命令、解析命令、执行命令、返回结果**等。

而在最近，redis 6.0 版本又一次引入了多线程概念，与 4.0 不同的是，这次的多线程会涉及到上述的核心流程。

**Redis 6.0*R* 中，**多线程主要用于网络 I/O 阶段**，也就是**接收命令**和**写回结果**阶段，而在**执行命令**阶段，还是由**单线程**串行执行。由于执行时还是串行，因此无需考虑并发安全问题。

值得注意的时，redis 中的多线程组不会同时存在“读”和“写”，这个多线程组只会同时“读”或者同时“写”。

------

#### redis 6.0 加入多线程 I/O 之后，处理命令的核心流程

暂时

------

#### 为什么 Redis 是单线程？

在 redis 6.0 之前，redis 的核心操作是单线程的。

因为 redis 是完全基于内存操作的，通常情况下CPU不会是redis的瓶颈，redis 的**瓶颈**最有可能是**机器内存的大小**和**网络带宽**。

既然CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了，因为如果使用多线程的话会更复杂，同时需要引入上下文切换、加锁等等，会带来额外的性能消耗。

而随着近些年互联网的不断发展，大家对于缓存的性能要求也越来越高了，因此 redis 也开始在逐渐往多线程方向发展。

最近的 **6.0 版本就对核心流程引入了多线程**，主要用于**解决 redis 在网络 I/O 上的性能瓶颈**。而对于核心的命令执行阶段，目前还是单线程的。

------

#### 为什么Redis使用单线程速度确很快

主要有以下几点：

1、基于内存的操作

2、使用了**I/O多路复用模型**，select、epoll 等，基于reactor 模式开发了自己的网络事件处理器

3、单线程可以避免不必要的上下文切换和竞争条件，减少了这方面的性能消耗。

4、以上这三点是 redis 性能高的主要原因，其他的还有一些小优化，例如：对数据结构进行了优化，简单动态字符串、压缩列表等。

------

#### Redis 常见的数据结构

基础的5种：

String：字符串，最基础的数据类型。

List：列表。

Hash：哈希对象。

Set：集合。

Sorted Set：有序集合，Set 的基础上加了个分值。

高级的4种：

HyperLogLog：通常用于基数统计。使用少量固定大小的内存，来统计集合中唯一元素的数量。统计结果不是精确值，而是一个带有0.81%标准差（standard error）的近似值。所以，HyperLogLog适用于一些对于统计结果精确度要求不是特别高的场景，例如网站的UV统计。

Geo：redis 3.2 版本的新特性。可以将用户给定的地理位置信息储存起来， 并对这些信息进行操作：获取2个位置的距离、根据给定地理位置坐标获取指定范围内的地理位置集合。

Bitmap：位图。

Stream：主要用于消息队列，类似于 kafka，可以认为是 pub/sub 的改进版。提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。
————————————————
版权声明：本文为CSDN博主「程序员囧辉」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/v123411739/article/details/116109674

------

#### redis数据结构---(Sorted Set)有序集合的实现

Sorted Set在数据少的时候，底层会使用ziplist【压缩表】数据结构存储数据。当一个Sorted Set的数据超过设置的阈值的时候，底层会改为zset数据结构，zset是由dict【字典】和skiplist【跳跃表存储数据】。

使用压缩列表实现，当保存的元素长度都小于64字节，同时数量小于128时，使用该编码方式，否则会使用 skiplist。这两个参数可以通过 zset-max-ziplist-entries、zset-max-ziplist-value 来自定义修改。

##### ziplist简介

参考https://blog.csdn.net/zgaoq/article/details/89710600

###### ziplist内存布局

![img](images/cdd98e7f7ee4ad8289b4efa770b0386f.png)

ziplist是由**一系列特殊编码的连续内存块组成的顺序存储结构**，类似于数组，ziplist在内存中是**连续存储**的，但是不同于数组，为了**节省内存** ziplist的每个元素所占的内存大小可以不同（数组中叫元素，ziplist叫节点entry），每个节点可以用来存储一个整数或者一个字符串。
下图是ziplist在内存中的布局

![img](images/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pnYW9x,size_16,color_FFFFFF,t_70.png)

zlbytes: ziplist的长度（单位: 字节)，是一个32位无符号整数
zltail: ziplist最后一个节点的偏移量，反向遍历ziplist或者pop尾部节点的时候有用。
zllen: ziplist的节点（entry）个数
entry: 节点
zlend: 值为0xFF，用于标记ziplist的结尾。

接下来我们看看节点的布局

节点的布局(entry)

每个节点由三部分组成：prevlength、encoding、data

prevlengh: 记录上一个节点的长度，为了方便反向遍历ziplist
encoding: 当前节点的编码规则，下文会详细说
data: 当前节点的值，可以是数字或字符串

* **节点的布局(entry)**

  每个节点由三部分组成：prevlength、encoding、data

  prevlengh: 记录上一个节点的长度，为了方便反向遍历ziplist

  encoding: 当前节点的编码规则，下文会详细说

  data: 当前节点的值，可以是数字或字符串 

  为了节省内存，**根据上一个节点的长度prevlength 可以将ziplist节点分为两类：**

  ![img](images/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pnYW9x,size_16,color_FFFFFF,t_70-164333964015317-164333964200319.png)

  entry的前8位小于254，则这8位就表示上一个节点的长度
  entry的前8位等于254，则意味着上一个节点的长度无法用8位表示，后面32位才是真实的prevlength。用254 不用255(11111111)作为分界是因为255是zlend的值，它用于判断ziplist是否到达尾部。

##### zset相关

zset结构体由**字典**和**跳跃表**组成，其中跳跃表按**分值**(score)**从小到大**保存所有集合元素，所以会是按照分值**有序**。而字典则保存着从**元素**到**分值**的映射，这样就可以用**O(1)**的复杂度来查找**元素**对应的**分值**。

字典主要由多个hashtable组成，后面在介绍hash结构的时候会说hashtable，这里的hash扩容和后面也是一样的

![img](images/5443eeb35a0b13a1970e447672c6185e.png)

先说说skipList，是参考以下链接来的

https://juejin.cn/post/6844903446475177998#heading-7
https://xie.infoq.cn/article/b1a46bb4a55303c9d8d8a5dcc

###### skiplist查找的流程

当查找元素时，会从最顶层链表的头节点开始遍历。以升序跳表为例，如果当前节点的下一个节点包含的值比目标元素值小，则继续向右查找。如果下一个节点的值比目标值大，就转到当前层的下一层去查找。重复向右和向下的操作，直到找到与目标值相等的元素为止。下图中的蓝色箭头标记出了查找元素 21 的步骤

![img](images/80f61dc5cb79d68252a72e52c136900f.png)

###### skiplist与平衡树、哈希表的比较

平衡树的定义：任意节点的子树的**高度差**都小于等于1

- skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。
- 在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。
- 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。
- 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。
- 查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。
- 从算法实现难度上来比较，skiplist比平衡树要简单得多。

###### Sorted Set 为什么使用跳跃表，而不是红黑树？

主要有以下几个原因：

* 跳表的性能和红黑树差不多。
* 跳表更容易实现和调试。
* skiplist占用内存更小
* 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂。而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。

###### 为啥redis的zset用跳表而不用b+树？

| 数据结构 | 实现原理           | key查询方式      | 查找效率 | 存储大小                                                     | 插入、删除效率                           |
| -------- | ------------------ | ---------------- | -------- | ------------------------------------------------------------ | ---------------------------------------- |
| Hash     | 哈希表             | 支持单key        | 接近O(1) | 小，除了数据没有额外的存储                                   | O(1)                                     |
| B+树     | 平衡二叉树扩展而来 | 单key,范围，分页 | O(Log(n) | 除了数据，还多了左右指针，以及叶子节点指针                   | O(Log(n)，需要调整树的结构，算法比较复杂 |
| 跳表     | 有序链表扩展而来   | 单key，分页      | O(Log(n) | 除了数据，还多了指针，但是每个节点的指针小于<2,所以比B+树占用空间小 | O(Log(n)，只用处理链表，算法比较简单     |

从上面表格可以看出跳表和b+树的查找，插入，删除效率都一样。但是，**很明显b+树占用的空间的更大**，显然不适合redis这种针对于内存的读取。由于是针对内存，**不涉及磁盘IO**，因此使用了跳表； 

###### 为啥mysql的索引不用跳表而用b+树？

因为B+树的原理是 叶子节点存储数据，非叶子节点存储索引，B+树的每个节点可以存储多个关键字，**它将节点大小设置为磁盘页[16k]的大小**，充分利用了磁盘预读的功能。每次读取磁盘页时就会读取一整个节点,每个叶子节点还有指向前后节点的指针，为的是最大限度的**降低磁盘的IO**;因为数据在内存中读取耗费的时间是从磁盘的IO读取的百万分之一。

#### redis数据结构---Hash的实现

Hash 对象当前有两种编码：**ziplist**、**hashtable**

**ziplist**：使用压缩列表实现，每当有新的键值对要加入到哈希对象时，程序会先将保存了键的节点推入到压缩列表的表尾，然后再将保存了值的节点推入到压缩列表表尾。

因此：

1）保存了同一键值对的两个节点总是紧挨在一起，保存键的节点在前，保存值的节点在后；

2）先添加到哈希对象中的键值对会被放在压缩列表的表头方向，而后来添加的会被放在表尾方向。
![img](images/425ac568260a02c3e2538994205d87b6.png)

**hashtable**：使用字典作为底层实现，哈希对象中的每个键值对都使用一个字典键值来保存，跟 java 中的 HashMap 类似。

![img](images/f23b809e036fe56a484c481c5802aedf.png)

##### Hash 对象的扩容流程

hash 对象在扩容时使用了一种叫“**渐进式 rehash**”的方式，步骤如下：

1.计算新表 size、掩码，为新表 ht[1] 分配空间，让字典同时持有 ht[0] 和 ht[1] 两个哈希表。

2.将 rehash 索引计数器变量 rehashidx 的值设置为0，表示 rehash 正式开始。

3.在 rehash 进行期间，每次对字典执行添加、删除、査找、更新操作时，程序除了执行指定的操作以外，还会触发额外的 rehash 操作，在源码中的 _dictRehashStep 方法。

_dictRehashStep：从名字也可以看出来，大意是 rehash 一步，也就是 rehash 一个索引位置。

该方法会从 ht[0] 表的 rehashidx 索引位置上开始向后查找，找到第一个不为空的索引位置，将该索引位置的所有节点 rehash 到 ht[1]，当本次 rehash 工作完成之后，将 ht[0] 索引位置为 rehashidx 的节点清空，同时将 rehashidx 属性的值加一。

4.将 rehash 分摊到每个操作上确实是非常妙的方式，但是万一此时服务器比较空闲，一直没有什么操作，难道 redis 要一直持有两个哈希表吗？

答案当然不是的。我们知道，redis 除了文件事件外，还有时间事件，redis 会定期触发时间事件，这些时间事件用于执行一些后台操作，其中就包含 rehash 操作：当 redis 发现有字典正在进行 rehash 操作时，会花费1毫秒的时间，一起帮忙进行 rehash。

5.随着操作的不断执行，最终在某个时间点上，ht[0] 的所有键值对都会被 rehash 至 ht[1]，此时 rehash 流程完成，会执行最后的清理工作：释放 ht[0] 的空间、将 ht[0] 指向 ht[1]、重置 ht[1]、重置 rehashidx 的值为 -1。

##### 渐进式 rehash 的优点

渐进式 rehash 的好处在于它采取分而治之的方式，将 rehash 键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式 rehash 而带来的庞大计算量。

在进行渐进式 rehash 的过程中，字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间，字典的删除、査找、更新等操作会在两个哈希表上进行。例如，要在字典里面査找一个键的话，程序会先在 ht[0] 里面进行査找，如果没找到的话，就会继续到 ht[1] 里面进行査找，诸如此类。

另外，在渐进式 rehash 执行期间，新增的键值对会被直接保存到 ht[1], ht[0] 不再进行任何添加操作，这样就保证了 ht[0] 包含的键值对数量会只减不增，并随着 rehash 操作的执行而最终变成空表。
